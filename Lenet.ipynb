{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lenet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO6sGp7+tzYQCA4Api3IFWU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coco401/deep-learning-models-in-tf2/blob/master/Lenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNsBSrTRFgR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import models,layers\n",
        "import numpy as np\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEwFPVd2N2ON",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "1cc5179a-28d5-4d5e-abe8-148d8ea7c1d8"
      },
      "source": [
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9at6a_55JR23",
        "colab_type": "text"
      },
      "source": [
        "Layer C1 is a convolution layer with six convolution kernels of 5x5 and the size of feature mapping is 28x28, which can prevent the information of the input image from falling out of the boundary of convolution kernel.\n",
        "\n",
        "Layer S2 is the subsampling/pooling layer that outputs 6 feature graphs of size 14x14. Each cell in each feature map is connected to 2x2 neighborhoods in the corresponding feature map in C1.\n",
        "\n",
        "Layer C3 is a convolution layer with 16 5-5 convolution kernels. The input of the first six C3 feature maps is each continuous subset of the three feature maps in S2, the input of the next six feature maps comes from the input of the four continuous subsets, and the input of the next three feature maps comes from the four discontinuous subsets. Finally, the input for the last feature graph comes from all feature graphs of S2.\n",
        "\n",
        "Layer S4 is similar to S2, with size of 2x2 and output of 16 5x5 feature graphs.\n",
        "\n",
        "Layer C5 is a convolution layer with 120 convolution kernels of size 5x5. Each cell is connected to the 5*5 neighborhood on all 16 feature graphs of S4. Here, since the feature graph size of S4 is also 5x5, the output size of C5 is 1*1. So S4 and C5 are completely connected. C5 is labeled as a convolutional layer instead of a fully connected layer, because if lenet-5 input becomes larger and its structure remains unchanged, its output size will be greater than 1x1, i.e. not a fully connected layer.\n",
        "\n",
        "F6 layer is fully connected to C5, and 84 feature graphs are output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBTe1idnGzE6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "outputId": "10c44ba8-db94-467c-d3a6-141c8b17cd7b"
      },
      "source": [
        "model = models.Sequential([\n",
        "  Input(shape = input_shape),\n",
        "  layers.Conv2D(6, 5,  activation='relu', padding = 'same'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(16, 5, activation='relu',padding = \"same\"),\n",
        "  layers.MaxPooling2D(), \n",
        "  layers.Conv2D(120, 5, activation='relu',padding = \"same\"),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(84, activation = 'tanh'),\n",
        "  layers.Dense(num_classes,activation=\"softmax\")\n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_39 (Conv2D)           (None, 28, 28, 6)         156       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_27 (MaxPooling (None, 14, 14, 6)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 14, 14, 16)        2416      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_28 (MaxPooling (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 7, 7, 120)         48120     \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 5880)              0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 84)                494004    \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 10)                850       \n",
            "=================================================================\n",
            "Total params: 545,546\n",
            "Trainable params: 545,546\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OP2dkJ8qPvG3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "035fd3bc-6ad4-4c54-f81f-74fbb0fbf367"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "422/422 [==============================] - 19s 46ms/step - loss: 0.4539 - accuracy: 0.8752 - val_loss: 0.1287 - val_accuracy: 0.9650\n",
            "Epoch 2/15\n",
            "422/422 [==============================] - 19s 45ms/step - loss: 0.1251 - accuracy: 0.9636 - val_loss: 0.0817 - val_accuracy: 0.9785\n",
            "Epoch 3/15\n",
            "422/422 [==============================] - 19s 45ms/step - loss: 0.0935 - accuracy: 0.9721 - val_loss: 0.0724 - val_accuracy: 0.9818\n",
            "Epoch 4/15\n",
            "422/422 [==============================] - 19s 45ms/step - loss: 0.0772 - accuracy: 0.9765 - val_loss: 0.0616 - val_accuracy: 0.9823\n",
            "Epoch 5/15\n",
            "422/422 [==============================] - 19s 45ms/step - loss: 0.0678 - accuracy: 0.9796 - val_loss: 0.0573 - val_accuracy: 0.9848\n",
            "Epoch 6/15\n",
            "422/422 [==============================] - 20s 46ms/step - loss: 0.0599 - accuracy: 0.9811 - val_loss: 0.0530 - val_accuracy: 0.9847\n",
            "Epoch 7/15\n",
            "422/422 [==============================] - 20s 46ms/step - loss: 0.0538 - accuracy: 0.9838 - val_loss: 0.0512 - val_accuracy: 0.9853\n",
            "Epoch 8/15\n",
            "422/422 [==============================] - 20s 47ms/step - loss: 0.0513 - accuracy: 0.9839 - val_loss: 0.0468 - val_accuracy: 0.9870\n",
            "Epoch 9/15\n",
            "422/422 [==============================] - 20s 46ms/step - loss: 0.0460 - accuracy: 0.9857 - val_loss: 0.0444 - val_accuracy: 0.9875\n",
            "Epoch 10/15\n",
            "422/422 [==============================] - 20s 46ms/step - loss: 0.0430 - accuracy: 0.9863 - val_loss: 0.0451 - val_accuracy: 0.9868\n",
            "Epoch 11/15\n",
            "422/422 [==============================] - 20s 47ms/step - loss: 0.0400 - accuracy: 0.9870 - val_loss: 0.0475 - val_accuracy: 0.9863\n",
            "Epoch 12/15\n",
            "422/422 [==============================] - 20s 47ms/step - loss: 0.0378 - accuracy: 0.9876 - val_loss: 0.0421 - val_accuracy: 0.9888\n",
            "Epoch 13/15\n",
            "422/422 [==============================] - 20s 46ms/step - loss: 0.0351 - accuracy: 0.9882 - val_loss: 0.0418 - val_accuracy: 0.9878\n",
            "Epoch 14/15\n",
            "422/422 [==============================] - 19s 46ms/step - loss: 0.0328 - accuracy: 0.9896 - val_loss: 0.0450 - val_accuracy: 0.9873\n",
            "Epoch 15/15\n",
            "422/422 [==============================] - 20s 46ms/step - loss: 0.0308 - accuracy: 0.9907 - val_loss: 0.0383 - val_accuracy: 0.9898\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f77e26026a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuyNitgoRU9o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "aa12f041-2dfd-48a0-c414-38ae88b74f1e"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.04211908206343651\n",
            "Test accuracy: 0.9869999885559082\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}